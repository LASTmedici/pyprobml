An error occurred while executing the following cell:
------------------
# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html
# http://www.pitt.edu/~naraehan/presentation/Movie+Reviews+sentiment+analysis+with+Scikit-Learn.html
# https://medium.com/@cristhianboujon/how-to-list-the-most-common-words-from-text-corpus-using-scikit-learn-dad4d0cab41d


import numpy as np
from numpy.testing import assert_allclose

corpus = [
    "This is the first example.",
    "This example is the second example",
    "Do you want to see more examples, or is three examples enough?",
]


from sklearn.feature_extraction.text import CountVectorizer

# default tokenizer drops important words, NLTK tokenzier keeps everything,
try:
    from nltk.tokenize import RegexpTokenizer
except ModuleNotFoundError:
    %pip install -qq nltk
    from nltk.tokenize import RegexpTokenizer

tokenizer = lambda s: RegexpTokenizer(r"\w+").tokenize(s)  # alphanumeric strings get tokenized
vectorizer = CountVectorizer(tokenizer=tokenizer)
B = vectorizer.fit_transform(corpus).todense()  # bag of words, (N,T)
print(vectorizer.get_feature_names())
[
    "do",
    "enough",
    "example",
    "examples",
    "first",
    "is",
    "more",
    "or",
    "second",
    "see",
    "the",
    "this",
    "three",
    "to",
    "want",
    "you",
]

print(B)
"""
[[0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0]
 [0 0 2 0 0 1 0 0 1 0 1 1 0 0 0 0]
 [1 1 0 2 0 1 1 1 0 1 0 0 1 1 1 1]]
"""

try:
    from tensorflow import keras
except ModuleNotFoundError:
    %pip install -qq tensorflow
    from tensorflow import keras

t = keras.preprocessing.text.Tokenizer()
t.fit_on_texts(corpus)
print(t.document_count)
print(t.word_counts)
print(t.word_docs)
print(t.word_index)
"""
3
OrderedDict([('this', 2), ('is', 3), ('the', 2), ('first', 1), ('example', 3),
 ('second', 1), ('do', 1), ('you', 1), ('want', 1), ('to', 1),
 ('see', 1), ('more', 1), ('examples', 2), ('or', 1), ('three', 1), ('enough', 1)])
defaultdict(<class 'int'>, {'first': 1, 'the': 2, 'is': 3, 'this': 2, 'example': 2, 
'second': 1, 'you': 1, 'see': 1, 'do': 1, 'or': 1, 'examples': 1, 'enough': 1,
 'three': 1, 'more': 1, 'want': 1, 'to': 1})
{'is': 1, 'example': 2, 'this': 3, 'the': 4, 'examples': 5, 'first': 6, 
'second': 7, 'do': 8, 'you': 9, 'want': 10, 'to': 11, 'see': 12, 'more': 13,
 'or': 14, 'three': 15, 'enough': 16}
"""

encoded_docs = t.texts_to_matrix(corpus, mode="count")
print(encoded_docs)
"""
[[0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 2. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 1. 0. 0. 0. 2. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]
"""
reverse_word_index = dict([(value, key) for (key, value) in t.word_index.items()])
"""
{1: 'is',
 2: 'example',
 3: 'this',
 4: 'the',
 5: 'examples',
 6: 'first',
 7: 'second',
 8: 'do',
 9: 'you',
 10: 'want',
 11: 'to',
 12: 'see',
 13: 'more',
 14: 'or',
 15: 'three',
 16: 'enough'}
"""

## TF transform
from sklearn.feature_extraction.text import TfidfTransformer

tf_transformer = TfidfTransformer(use_idf=False).fit(B)
Btf = tf_transformer.transform(B).todense()
# Compute TF matrix "manually"
# Btf[i,j] = L2-normalize(tf[i,:])_j
from sklearn.preprocessing import normalize

assert_allclose(Btf, normalize(B), atol=1e-2)
assert_allclose(Btf, B / np.sqrt(np.sum(np.power(B, 2), axis=1)), atol=1e-2)


## TF-IDF transform
tfidf_transformer = TfidfTransformer(use_idf=True, smooth_idf=True)
Btfidf = tfidf_transformer.fit_transform(B).todense()
# Compute idf "manually"
Bbin = B > 0  # Bbin[i,j]=1 iff word j occurs at least once in doc i
df = np.ravel(np.sum(Bbin, axis=0))  # convert from (1,T) to (T)
n = np.shape(B)[0]
idf = np.log((1 + n) / (1 + df)) + 1
assert_allclose(idf, tfidf_transformer.idf_, atol=1e-2)
# Compute tf-idf "manually"
tfidf = normalize(np.multiply(B, idf))
assert_allclose(tfidf, Btfidf, atol=1e-2)


# Make a pipeline
from sklearn.pipeline import Pipeline

pipeline = Pipeline(
    [("bow", CountVectorizer(tokenizer=tokenizer)), ("tfidf", TfidfTransformer(use_idf=True, smooth_idf=True))]
)
Btrain = pipeline.fit_transform(corpus).todense()
assert_allclose(Btfidf, Btrain)

corpus_test = ["This example is a new document.", "And this is the second test."]
Btest = pipeline.transform(corpus_test)
print(np.round(Btest.todense(), 3))
"""
[[0.    0.    0.62  0.    0.    0.481 0.    0.    0.    0.    0.    0.62
  0.    0.    0.    0.   ]
 [0.    0.    0.    0.    0.    0.373 0.    0.    0.632 0.    0.48  0.48
  0.    0.    0.    0.   ]]
"""
------------------

---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/tmp/ipykernel_5356/2355378358.py in <module>
     54 
     55 try:
---> 56     from tensorflow import keras
     57 except ModuleNotFoundError:
     58     get_ipython().run_line_magic('pip', 'install -qq tensorflow')

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/__init__.py in <module>
     49 from ._api.v2 import autograph
     50 from ._api.v2 import bitwise
---> 51 from ._api.v2 import compat
     52 from ._api.v2 import config
     53 from ._api.v2 import data

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/__init__.py in <module>
     35 import sys as _sys
     36 
---> 37 from . import v1
     38 from . import v2
     39 from tensorflow.python.compat.compat import forward_compatibility_horizon

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/__init__.py in <module>
     28 from . import autograph
     29 from . import bitwise
---> 30 from . import compat
     31 from . import config
     32 from . import data

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py in <module>
     35 import sys as _sys
     36 
---> 37 from . import v1
     38 from . import v2
     39 from tensorflow.python.compat.compat import forward_compatibility_horizon

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/compat/v1/__init__.py in <module>
     45 from tensorflow._api.v2.compat.v1 import layers
     46 from tensorflow._api.v2.compat.v1 import linalg
---> 47 from tensorflow._api.v2.compat.v1 import lite
     48 from tensorflow._api.v2.compat.v1 import logging
     49 from tensorflow._api.v2.compat.v1 import lookup

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/lite/__init__.py in <module>
      7 
      8 from . import constants
----> 9 from . import experimental
     10 from tensorflow.lite.python.lite import Interpreter
     11 from tensorflow.lite.python.lite import OpHint

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/__init__.py in <module>
      6 import sys as _sys
      7 
----> 8 from . import authoring
      9 from tensorflow.lite.python.analyzer import ModelAnalyzer as Analyzer
     10 from tensorflow.lite.python.lite import OpResolverType

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/_api/v2/compat/v1/lite/experimental/authoring/__init__.py in <module>
      6 import sys as _sys
      7 
----> 8 from tensorflow.lite.python.authoring.authoring import compatible

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/lite/python/authoring/authoring.py in <module>
     41 
     42 # pylint: disable=g-import-not-at-top
---> 43 from tensorflow.lite.python import convert
     44 from tensorflow.lite.python import lite
     45 from tensorflow.lite.python.metrics import converter_error_data_pb2

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/lite/python/convert.py in <module>
     26 
     27 from tensorflow.lite.python import lite_constants
---> 28 from tensorflow.lite.python import util
     29 from tensorflow.lite.python import wrap_toco
     30 from tensorflow.lite.python.convert_phase import Component

~/miniconda3/envs/py37/lib/python3.7/site-packages/tensorflow/lite/python/util.py in <module>
     53 # pylint: disable=unused-import
     54 try:
---> 55   from jax import xla_computation as _xla_computation
     56 except ImportError:
     57   _xla_computation = None

~/miniconda3/envs/py37/lib/python3.7/site-packages/jax/__init__.py in <module>
     33 # We want the exported object to be the class, so we first import the module
     34 # to make sure a later import doesn't overwrite the class.
---> 35 from jax import config as _config_module
     36 del _config_module
     37 

~/miniconda3/envs/py37/lib/python3.7/site-packages/jax/config.py in <module>
     15 # TODO(phawkins): fix users of this alias and delete this file.
     16 
---> 17 from jax._src.config import config

~/miniconda3/envs/py37/lib/python3.7/site-packages/jax/_src/config.py in <module>
     27 from absl import logging
     28 
---> 29 from jax._src import lib
     30 from jax._src.lib import jax_jit
     31 from jax._src.lib import transfer_guard_lib

~/miniconda3/envs/py37/lib/python3.7/site-packages/jax/_src/lib/__init__.py in <module>
     95   jax_version=jax.version.__version__,
     96   jaxlib_version=jaxlib.version.__version__,
---> 97   minimum_jaxlib_version=jax.version._minimum_jaxlib_version)
     98 
     99 

~/miniconda3/envs/py37/lib/python3.7/site-packages/jax/_src/lib/__init__.py in check_jaxlib_version(jax_version, jaxlib_version, minimum_jaxlib_version)
     87            f'incompatible with jax version {jax_version}. Please '
     88            'update your jax and/or jaxlib packages.')
---> 89     raise RuntimeError(msg)
     90 
     91   return _jaxlib_version

RuntimeError: jaxlib version 0.3.15 is newer than and incompatible with jax version 0.3.14. Please update your jax and/or jaxlib packages.
RuntimeError: jaxlib version 0.3.15 is newer than and incompatible with jax version 0.3.14. Please update your jax and/or jaxlib packages.
